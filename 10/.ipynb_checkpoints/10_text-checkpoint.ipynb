{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf36a7c5",
   "metadata": {},
   "source": [
    "# 実践機械学習（本）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd40c2e",
   "metadata": {},
   "source": [
    "## とりあえずメモ\n",
    "- ANN:artificial neural neteworks\n",
    "    - ANNは柔軟、強力、スケーラブルで、数十億の画像を分類したり（たとえば、Google画像検索）、音声認識サービスを支えたり（たとえば、Apple のSiri）、毎日数億人のユーザーにお勧めビデオを推薦したり（たとえば、YouTube）、囲碁の対局で世界チャンピオンを負かせる方法を学習する（DeepMindのAlphaGo）、といった大規模で高度に複雑な機械学習タスクに挑戦するためには理想的な存在である。\n",
    "    - 第II 部では、広く使われているKeras API を使ってニューラルネットワークを実装する方法を見ていく\n",
    "        - Keras は、ニューラルネットワークを構築、訓練、評価、実行するための単純で高水準なAPI として見事な設計になっている。\n",
    "        \n",
    "- ANNが深い隠れ層を保つ場合†9、そのANNは深層ニューラルネットワーク（DNN：deep neuralnetwork）と呼ばれる\n",
    ">勾配降下アルゴリズ\n",
    "ムは、個々の訓練インスタンスに対して、まず予測を行い（前進パス）、誤差を計算してから、各\n",
    "層を逆戻りしながら個々の接続部が誤差にどの程度の影響を与えたかを計測し（後退パス）、最後\n",
    "に誤差が小さくなるように接続重みを調整する（勾配降下ステップ）。\n",
    "\n",
    "\n",
    "## 10.1.5章\n",
    "- 住宅価格一つの予測 → 一つの出力\n",
    "- 画像中心 → ２つの出力\n",
    "- バウンディングボックスの中心 → ４つの出力\n",
    "- 予測したいものに合わせて出力ニューロンの数を増やせばいい\n",
    "- MSE（平均２乗誤差）、MAE(平均絶対誤差)のそれぞれの欠点を補うように、フーバー損失関数がある\n",
    "- [［損失関数］Huber損失（Huber Loss）／Smooth L1 Lossとは？](https://atmarkit.itmedia.co.jp/ait/articles/2108/04/news031.html)\n",
    "    - MSE: 二乗しているため、外れ値の影響を大きく受ける\n",
    "    - MAE: 誤差がゼロの地点で微分不可能、ゼロに近い場所で勾配が大きいまま\n",
    "    \n",
    "    \n",
    "## 10.1.6章\n",
    "- 二項分類問題 → シグモイド関数を活性化関数とする一個の出力ニューロン\n",
    "- 多ラベル二項分類 →\n",
    "- 個々のインスタンスが三個以上のクラスの中の\n",
    "\n",
    "## 章末問題 \n",
    "### 1. [Tinker With a Neural Network Right Here in Your Browser.](https://playground.tensorflow.org/#activation=relu&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=8,2&seed=0.24701&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "- 層を増やせば収束速度が早くなるというわけではない？？\n",
    "- 使う活性化関数によって、分類の境界線の形が異なる\n",
    "- ニューロンを増やすと、学習速度が向上する？？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dd137",
   "metadata": {},
   "source": [
    "\n",
    "## 分からないことメモ\n",
    ">パーセプトロンの学習アルゴリズムが確率的勾配降下法とよく似ていることに気づかれたかもしれない p289\n",
    "- **確率的勾配降下法の理論を知らない**\n",
    ">ロジスティック回帰分類器とは異なり、パーセプトロンはクラスに属する確率を出力しないこと\n",
    "に注意していただきたい。パーセプトロンは、ハード投票分類をするだけである。これは、パーセ\n",
    "プトロンよりもロジスティック回帰を使うべきよい理由の1 つになっている。 p289\n",
    "\n",
    "- **隠れ層や入力層にあるバイアスベクトルの役割は何か？？**\n",
    "\n",
    ">勾配降下アルゴリズ\n",
    "ムは、個々の訓練インスタンスに対して、まず予測を行い（前進パス）、誤差を計算してから、各\n",
    "層を逆戻りしながら個々の接続部が誤差にどの程度の影響を与えたかを計測し（後退パス）、最後\n",
    "に誤差が小さくなるように接続重みを調整する（勾配降下ステップ）。 p292\n",
    "- **この文章は何となく分かるのだが、実際に数学的解釈がしたい**\n",
    "\n",
    ">すべての隠れ層の接続重みを無作為に初期化することが大切であり、そうしないと訓練が失敗\n",
    "する。たとえば、すべての重みとバイアスを0で初期化すると、特定の層のすべてのニューロ\n",
    "ンが完全に同じになり、バックプロパゲーションはそれらに同じように影響を与えるため、重\n",
    "みはすべて同じのままになってしまう。言い換えれば、1 つの層に数百個ものニューロンを用\n",
    "意しても、モデルはまるで層に1 つのニューロンしか無いのと同じようになってしまうのだ。\n",
    "これは賢明なことではないだろう。重みを無作為に初期化すれば、対称性が破られ、バック\n",
    "プロパゲーションがニューロンを多様な形で訓練できる。  p292\n",
    "- **この文章は何となく分かるが、、、、、**\n",
    "\n",
    ">ステップ関数はフラットな線分だけで構成されるため、相手にできる勾配\n",
    "がない（勾配降下法は、平面では動きが取れない）が、ロジスティック関数なら、あらゆる位置に明\n",
    "確に定義された非0 の導関数があるため、勾配降下法は各ステップで何らかの形で前に進むことができる p292\n",
    "\n",
    "- **勾配降下法と活性化関数の関わり方がよくわからない**\n",
    "    - 更に、損失関数と勾配の関係が知りたい、フーバー損失関数のところでMAEと勾配について語られていた\n",
    "- **なぜ活性化関数として、ReLU関数やシグモイド関数などが重みを最適化する（バッグプロパゲーション）のに有効に働くのかが分からない → 導関数が0になる箇所があるから？？**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e092dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420daaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a408dea5",
   "metadata": {},
   "source": [
    "# 生成ディープラーニング（本）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f099f",
   "metadata": {},
   "source": [
    "## わからないことをメモ\n",
    "- 誤差逆伝播とは？？どのような理屈なのか？？p38\n",
    ">ディープラーニングのメカニズムを正しく理解するのに重要\n",
    "なことの大部分は、データがニューラルネットワークを流れるにつれて、ネットワー\n",
    "クの各層がそのデータの形状をどのように変えていくかを理解することなのです。p３９\n",
    "- エポックとは？？p49\n",
    "- バッチとは？p49 → ミニバッチ学習とは？？\n",
    "- パディングとは？？p55\n",
    "- 四次元のテンソルとは？？p55\n",
    "    - 行列の次元を増やしたもの（行列に厚みを付けたもの）という理解でいいか？？\n",
    "- ミニバッチとは p60\n",
    "\n",
    ">この章から得るべき重要なポイントは、ディープニューラルネットワークはそのデザインに完全な柔軟性があり、モデルのアーキテクチャの設計には決まった規則はないということです\n",
    "\n",
    ">もう1 つ覚えておくべきポイントは、畳み込みを行うのはディープニューラル\n",
    "ネットワーク内の層であり、ネットワーク自身ではないことです\n",
    "\n",
    "- モデルを作成する p42\n",
    "- p47 損失関数の使い分け\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b87357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453b26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da17b6bb",
   "metadata": {},
   "source": [
    "# qiita記事\n",
    "[Convolutional Neural Networkとは何なのか](https://qiita.com/icoxfog417/items/5fd55fad152231d706c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2fb995",
   "metadata": {},
   "source": [
    "## とりあえずわからないことを列挙してみる\n",
    ">ただ、図の青い四角の中は概ね「右上から左下にかけて黒」という傾向があります。つまり、1ピクセルではなくある程度の広さの領域をまとめて入力にすることができれば、より精度の高い判定ができそうです。\n",
    "- 本当により精度の高い判定ができるのか。畳み込みという作業が本当に有効なのかどうか違和感がある。普通にピクセルごとに入力層に入力したほうが精度の高いモデルができるのではないだろうか？？\n",
    ">このフィルタを使った「畳み込む」という処理は、具体的には「フィルタ内の画像のベクトル」と「畳み込みに使用するベクトル」との間の掛け算、内積になります\n",
    "- フィルタとは\n",
    "    - 画像上の小領域のことを示し、一つの特徴量として圧縮する（畳み込む）\n",
    "- 畳み込みに使用するベクトルとは\n",
    ">フィルタの種類を増やせばその分Convolution Layerも増えていくことになります。\n",
    "- フィルタの種類を増やすとはどういうことか \n",
    ">Convolution Layerはフィルタを移動させながら適用することで作成し、フィルタの数だけ作成される。これを重ねて活性化関数(ReLU等)で繋いでいくことで、ネットワークを構築する。\n",
    "- 理論は分からないが、フィルタを移動しながら元データに適用  → これらを重ねて活性化関数でつなげていく\n",
    "- 活性化関数（ReLUがよく使われる）って何だっけ？？\n",
    "- 重ねるとはどういうことか？？\n",
    "- それとも、入力層に生成したもののピクセルデータを与えるだけではないのか？？？\n",
    ">パディングは、以下のように画像の端の領域を0で埋める処理になります。\n",
    ">なぜこんなことをするかというと、普通に畳み込みを行うと端の領域はほかの領域に比べて畳み込まれる回数が少なくなってしまうためです。このように画像の端を0で埋め、そこからフィルタをかけていくことで端もほかの領域と同様に反映されるようにします\n",
    "- フィルタの設定パラメータの意味がよくわからない\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7704042",
   "metadata": {},
   "source": [
    "## CNNモデルを理解するための勉強内容を抽出（分からないこと）\n",
    "- 畳み込みとは何か？？畳み込み層とは何か？？\n",
    "- 活性化関数とは何か？？なぜ必要なのか？？どんな種類があるのか？？\n",
    "- フィルタの設定パラメータ（フィルタの数、大きさ、移動幅、パディング）の意味\n",
    "- 各レイヤでやっていること\n",
    "    - Convolutional Layer：特徴量の畳み込みを行う層\n",
    "    - Pooling Layer：レイヤの縮小を行い、扱いやすくするための層\n",
    "    - Fully Connected Layer：特徴量から最終的な判定を行う層\n",
    "- （追加）バックプロパゲーションとはなにか？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a7916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de03ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0bc7e79",
   "metadata": {},
   "source": [
    "# YouTube記事まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4267dac",
   "metadata": {},
   "source": [
    "- [高校数学からはじめる深層学習入門(畳み込みニューラルネットワークの理解)](https://www.youtube.com/watch?v=xzzTYL90M8s)\n",
    "- [絶対に理解させる誤差逆伝播法【深層学習】](https://www.youtube.com/watch?v=0itH0iDO8BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7968a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dedbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22648b7b",
   "metadata": {},
   "source": [
    "# 全体進捗メモ\n",
    "\n",
    "## 2021-10-05やること\n",
    "- 昨日、抽出した勉強内容について「実践機械学習（本）」をもとに考察してみる\n",
    "\t- 特に10章以降のニューラルネットの部分を勉強してみる\n",
    "- （本のどこに何が書いてあるのか把握する）\n",
    "\n",
    "### 抽出内容\n",
    "- 畳み込みとは何か？？畳み込み層とは何か？？\n",
    "- 活性化関数とは何か？？なぜ必要なのか？？どんな種類があるのか？？\n",
    "- フィルタの設定パラメータ（フィルタの数、大きさ、移動幅、パディング）の意味\n",
    "- 各レイヤでやっていること\n",
    "    - Convolutional Layer：特徴量の畳み込みを行う層\n",
    "    - Pooling Layer：レイヤの縮小を行い、扱いやすくするための層\n",
    "    - Fully Connected Layer：特徴量から最終的な判定を行う層\n",
    "- （追加）バックプロパゲーションとはなにか？？\n",
    "\n",
    "### 現状：\n",
    "    - 本のどこに何が書いてあるのか把握しきれていない\n",
    "    - 畳み込みニューラルネットワークについてどこから学び始めるかまだ決めていない\n",
    "    - まだ実装していない\n",
    "    - 実装してから分からない理論などを勉強する\n",
    "    \n",
    "### 実績\n",
    "- 畳み込みニューラルネットワークの概要の理解を懸川さんと確認 → 間違いを指摘してもらった\n",
    "- 実践機械学習（本）/10章/ パーセプトロンの考察\n",
    "\n",
    "## 2021/10/06やること\n",
    "- 10章以降/ニューラルネットワークの基本/パーセプトロン\n",
    "\n",
    "\n",
    "### 現状（最近決めたこと）\n",
    "- データの可視化、データの前処理、アルゴリズムの選定、モデル学習、モデル検証の流れがあるとする\n",
    "- 目的は、CNNでMNISTデータを分類すること\n",
    "- まずは、CNNを知ることから始める\n",
    "- そのためには、ニューラルネットワークの基本について知ることが必須である\n",
    "- よって10章から入り、分からないこと、知らないことが出てきたら、３，４章を学習するというトップダウンの手順を踏んで見る\n",
    "- なお、勉強手順に関しては懸川さんと相談の上、いまだ模索中である。\n",
    "\n",
    "### 実績\n",
    "- MLPがXor問題を解決することが手計算をして理解した\n",
    "- 誤差逆伝播法について文章だけでは理解できなかったため、数学的に理解したい\n",
    "- KerasによるMLPの実装の一部（データセットを格納するところだけ）を行った\n",
    "\n",
    "\n",
    "## 2021-10-07やること\n",
    "- 10章以降/ニューラルネットワークの基本/KerasによるMLPの実装\n",
    "- EPCDepth モデル試運転\n",
    "- インタビュー\n",
    "\n",
    "### 実績\n",
    "- EPCDepthモデルの試運転が出来た\n",
    "- おもろ場インタビュー\n",
    "- KerasによるMLPの実装(←少し）\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd54d024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c50096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a11e284",
   "metadata": {},
   "source": [
    "# 実装例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919478d6",
   "metadata": {},
   "source": [
    "## 実践機械学習（本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed38e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "314d2d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2504/2269547353.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = (iris.target == 0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data[:, (2,3)]\n",
    "y = (iris.target == 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6df42ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddeba1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9457c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381ed2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9feb988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf0ee379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b26f8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0dee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ecf95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf45b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f3b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a972a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3ea9ac5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0e4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
