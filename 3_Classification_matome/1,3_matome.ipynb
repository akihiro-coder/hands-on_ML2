{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbe4e75",
   "metadata": {},
   "source": [
    "# 1章まとめ\n",
    "\n",
    "## 機械学習とは\n",
    "- 本書では、「コンピュータがデータから学習できるようにするためのコンピュータ・プログラミングについての科学」と定義している\n",
    "- 自分は、機械学習について「一定数あるデータから予測モデルを作って、その予測モデルを現場に導入して、自動的（図1-3）に新たなデータを使って再度予測モデルを作り直して行き、それを繰り返して、より精度の高い予測モデルを作り上げていく過程」と理解している。\n",
    "\n",
    "## 機械学習システムのタイプ\n",
    "1. 訓練に人間が関与するか（教師あり/なし, 半教師あり, 強化学習）\n",
    "2. その場で学習するか（オンライン, バッチ学習）\n",
    "3. 新しいデータと既知のデータを比較するか, または, 訓練データを用いて予測モデルを構築するか（インスタンスベース学習、モデルベース学習）\n",
    "\n",
    "\n",
    "これらは組み合わせて使うことが出来る。スパムメール分類システム（スパムかハムかを分類する）を例に取ると、「DNN（深層ニューラルネットワーク）モデル」を使用して「その場」で学習していくかもしれないケースは、「オンライン学習」✕「モデルベース学習」✕「教師あり学習」となる。\n",
    "\n",
    "### 1,2,3の内容を詳しく\n",
    "1. 教師あり/なし, 半教師あり, 強化学習（人間の関与の有無で分類）\n",
    "\n",
    "![](image1.PNG)\n",
    "\n",
    "![](image2.PNG)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. バッチ学習、オンライン学習（その場で学習するかで分類）\n",
    "![](image3.PNG)\n",
    "- オンライン学習の指標となる「学習速度」\n",
    " - 学習速度が早くする\n",
    "  - システムは新しいデータにすぐに対応する。しかし、古いデータをすぐに忘れる（外れ値データの影響を受けやすい） \n",
    " - 学習速度が遅くする\n",
    "  - 新しいデータに早く対応しない。しかし、外れ値データの影響を受けにくい。 \n",
    "<br>\n",
    "- __疑問点：バッチ学習が向いているケースは？？__\n",
    "<br>\n",
    "3. インスタンスベース学習、モデルベース学習（汎化の方法で分類）\n",
    "![](image4.PNG)\n",
    "- __疑問点： インスタンスベースが使われるケースは？？__\n",
    "\n",
    "\n",
    "\n",
    "## モデル学習の注意点\n",
    "1. 訓練セットに以下のような問題が生じているとシステムの性能が上がらない\n",
    "- 訓練セットが小さい\n",
    "- 訓練セット内のデータが全体を代表するものでない\n",
    "- 訓練セット内にノイズが多い\n",
    "- 無関係な特徴量が多い\n",
    "\n",
    "どうすればいい？？\n",
    "- より多くの訓練データを集める\n",
    "- 外れ値は取り除くか、手作業で修正する\n",
    "\n",
    "2. モデル作成時に以下のようなケースでは問題が生じる場合がある\n",
    "- モデルが単純すぎる（パラメータが少ない）　→　過小適合\n",
    "- モデルが複雑すぎる（パラメータが多すぎる）　→　過学習（特に訓練データ外れ値がありデータ量が少ない場合）\n",
    "\n",
    "過学習対策\n",
    "- パラメータが少ないモデルを選択\n",
    "- 訓練データ内の属性を減らす\n",
    "- モデルそのものに制約をかける　→　正則化\n",
    "- 訓練データ内のノイズを除去する\n",
    "\n",
    "\n",
    "正則化とは？\n",
    "<br>\n",
    "過学習のリスクを軽減するためにモデルに制約をかける\n",
    "<br>\n",
    "（例）多次元高次式　→　線形式　→　傾きと切片の両方またはどちらかに制限（固定や範囲を指定）をかける\n",
    "<br>\n",
    "正則化の程度は、学習アルゴリズムのパラメータ（ハイパーパラメータ）を操作して調整する。\n",
    "<br>\n",
    "注意点として、ハイパーパラメータを操作すれば過学習のリスクは減る一方で、「よい発見」はしにくくなる。\n",
    "\n",
    "\n",
    "\n",
    "## テスト工程\n",
    "\n",
    "![](test.PNG)\n",
    "<br>\n",
    "テストデータ：モデルの精度をテストするためのデータ。最後に一度だけ使用する。\n",
    "<br>\n",
    "訓練データ：パラメータの学習用。精度を高めるために、複数回使用してもいい。\n",
    "<br>\n",
    "ハイパーパラメータを調整する場合は、訓練データとは別に検証データを用意する、または、訓練データを分割して検証データを用意する。\n",
    "<br>\n",
    "その後、検証データを使って、汎化性能の評価やハイパーパラメータを調整する。\n",
    "\n",
    "\n",
    "\n",
    "## 1章でわからないこと\n",
    "- 半教師学習の学習方法\n",
    "<br>\n",
    "__半教師学習について下記の手順をたどる認識であるが、レビューを頂きたい。__\n",
    "\n",
    " 1. ラベル付きデータで教師あり学習でモデルを学習\n",
    " <br>\n",
    " 2. ラベルなしデータを教師なし学習アルゴリズムでクラスタリング\n",
    " <br>\n",
    " 3. クラスタリングの結果よりデータにラベルを付加\n",
    " <br>\n",
    " 4. ラベル付けしたデータを訓練データに追加\n",
    " <br>\n",
    " 5. 1のモデルを再学習\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "- __バッチ学習が向いているケース__\n",
    "- __インスタンスベースが使われるケース__\n",
    "- __インスタンスベース学習とモデルベース学習の「訓練データが汎化の対象となる未知データをよく代表するものになっていることが重要であるということ」とは、具体的にどのようなケースが「よく代表するもの」と言えるのか？？__\n",
    "- __訓練-開発セットはどのように作られるのか？？__\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# 3章まとめ\n",
    "## 進めたところ（まだ途中）\n",
    "- 3.1 MNIST\n",
    "- 3.2 二項分類器の訓練\n",
    "- 3.3 性能指標\n",
    " - 交差検証を使った正解率の測定\n",
    " - 混同行列\n",
    " - 適合率と再現率\n",
    " - 適合率と再現率のトレードオフ\n",
    " - ROC曲線\n",
    "\n",
    "## 読み進めたところまでの内容　流れ\n",
    "- データセット：MNISTデータ\n",
    "- 分類器：SGDClassifierクラス\n",
    "\n",
    "\n",
    "\n",
    "- 分類器を使用して、5の画像を5と予測できるか試してみる（k分割交差検証を試す）\n",
    "- 5と5以外の分類性能それぞれの「正解率」が90%超え　→　本当にいいのか悪いのか？？\n",
    " - 実際は5の画像データが全体の約10%あるからであり、「分類性能評価結果の数値」としては適切ではない可能性が高い\n",
    "\n",
    "\n",
    "- そこで他の分類性能指標（評価方法）を導入してみる\n",
    "- 混同行列を導入して適合率と再現率を導出して、分類器性能を再評価してみる\n",
    " - 適合率と再現率それぞれを単体で評価指標にしてもいい\n",
    " - それはプロジェクト（その時の問題や場合）に依る\n",
    " - つまり適合率か再現率のどちらかが大きくなるようなモデルを作成する場合がある\n",
    "\n",
    "- ２つの分類器の性能比較をするための方法として調和平均（F1値）を使用するケースがある\n",
    "- 調和平均は式から読み取るに、両者のそれぞれが小さくなると大きく変化する（1/xの変化率はx^2だから）\n",
    "- 言い換えると、調和平均は両者の確率が大きくなるとそれ程変わらないが、小さくなると敏感に反応して小さくなる\n",
    "\n",
    "<!-- \n",
    "↓懸川さんに教えてもらった\n",
    "２つの分類器それぞれの分類性能が悪いと、調和平均を用いることで敏感に両者を比較することが出来る\n",
    "（逆に、両者の分類性能が良いと、調和平均の値が類似している可能性があり、調和平均の値が、どちらの分類器の性能がいいのかの判断指標として使いにくい）\n",
    " -->\n",
    " \n",
    "\n",
    "\n",
    "- ここで、適合率と再現率の関係性を理解するために、「決定しきい値」を導入してみる\n",
    "- 決定しきい値は、しきい値よりもスコアが大きいと画像データを陽性とみなす\n",
    "- 導入すると適合率と再現率が「トレードオフな関係である」ことが分かる\n",
    "\n",
    "\n",
    "- トレードオフな関係であることが分かったので、両者のバランスを取る必要性が出てくる\n",
    "- 本書では、適合率と再現率を直接対決させた図を紹介している　→　図3-5\n",
    "- 急激な変化をもたらす部分は除くとして、適合率もしくは再現率を関数の引数に与えてやれば、その値を取る再現率と適合率のセットを求めることが出来る\n",
    "\n",
    "\n",
    "## 混同行列\n",
    "(改めて)scikit-learnを使用して、5と5以外の画像を分類し、分類精度をK分割交差検証（分割数3）を用いて評価した。\n",
    "<br>\n",
    "結果は以下のようになった。\n",
    "<br>\n",
    "![](再現率と適合率.PNG)\n",
    "<br>\n",
    "![](再現率と適合率のテキスト図.PNG)\n",
    "\n",
    "### 自分の認識の確認\n",
    "適合率とは、「予測した結果、どれだけ陽性を当てられるか？？」\n",
    "<br>\n",
    "再現率とは、「どれだけの割合で陽性を抽出できるか？？」\n",
    "\n",
    "## 調和平均について\n",
    "本書では、「２つの分類器を比較するための単純な方法」として調和平均(F1値)を求めて比較すると書かれていた。\n",
    "<br>\n",
    "調和平均の存在目的がいまいち分からない。\n",
    "<br>\n",
    "![](調和平均.PNG)\n",
    "<br>\n",
    "現状の理解として、\n",
    "<br>\n",
    "- 1/xはxの二乗で変化していくため、xが小さくと大きく1/xが変化する\n",
    "- ２つの分類器の性能がどちらも悪い場合(xが両者とも小さい場合)に、より性能がいい方を選択する指標として調和平均を導入する\n",
    "<br>\n",
    "という認識である。\n",
    "- 複数の分類器を比較評価する場合、再現率と適合率の両方をそれぞれ比較するだけで駄目なのか？？\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 適合率と再現率のトレードオフな関係について\n",
    "![](トレードオフ.PNG)\n",
    "<br>\n",
    "- 決定関数によって各画像が5に近いかどうか、スコアで表示される。\n",
    "- 右にあるほど、5と認識されやすい画像データが並ぶ。\n",
    "- 決定しきい値は、それの右にある画像は陽性、つまり5とみなされる仕組み。\n",
    "- しきい値が上がれば陽性と予測された、つまり5と予測される画像が増えてくるため、適合率が上がってくる。\n",
    "- しきい値が上がれば、いくつか本来5と予測された画像を取り逃すため、再現率が下がってくる。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 理解した箇所\n",
    "![](適合率と再現率の比較.PNG)\n",
    "- 決定しきい値と適合率、再現率のグラフについて（以下、自分の解釈）\n",
    " - しきい値を下げるほど、\n",
    "   - 適合率：陽性と予測する数が増えるがターゲット（今回は5の画像）の数は変わらないため、一定値(0%ではない)に近づく\n",
    "   - 再現率：実際の陽性データを、より多く「陽性」と抽出することになり、100%に近づく \n",
    " - しきい値を上げるほど、\n",
    "   - 適合率：しきい値の右にある数字画像の5の個数が増えてくる（しかし、他の数値データも含まれている可能性がある）ため、グラフはガタつきながら100%に近づく\n",
    "   - 再現率：しきい値の左にある本来の5と認識されていたであろう画像が陰性とみなされるため、徐々に0%に近づく\n",
    "  \n",
    "  \n",
    "## 疑問点\n",
    "\n",
    "<!-- ![](適合率と再現率グラフ.PNG)\n",
    "![](再現率と偽陽性率のグラフ.PNG) -->\n",
    "<!-- <img src=\"適合率と再現率グラフ.PNG\" width=\"10\"> -->\n",
    "<img src=\"適合率と再現率グラフ.PNG\" alt=\"\" width=\"600\" height=\"300\"> \n",
    "<img src=\"再現率と偽陽性率のグラフ.PNG\" alt=\"\" width=\"600\" height=\"300\">\n",
    "\n",
    "ROC 曲線はPR（適合率／再現率）曲線とよく似ているので、どちらを使ったらよいか迷う\n",
    "かもしれない。\n",
    "__目安としては、陽性クラスが珍しいとか、偽陰性よりも偽陽性の方が気になる\n",
    "というときにPR曲線を使い、それ以外のときはROC曲線を使うとよい。たとえば、先ほど\n",
    "のROC曲線（とROC AUCスコア）を見ると、この分類器はかなり性能が高いと思うかも\n",
    "しれないが、それは主として陽性（5）が陰性（5以外）と比べて少ないからである。__\n",
    "それに対し、PR曲線を見れば、この分類器には改善の余地が十分にある（曲線はもっと右上隅に近付\n",
    "けられる）ことが明らかになる。（テキストp100から参照）\n",
    "\n",
    "__太字__箇所の文章が理解できない\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c842fd83",
   "metadata": {},
   "source": [
    "<img src=\"適合率と再現率グラフ.PNG\" width=\"10\">\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
